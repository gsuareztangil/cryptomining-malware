import requests, json,os
from datetime import datetime
import networkx as nx
import dns.resolver
from collections import defaultdict
from urlparse import urlparse
import pandas as pd
import socket
import operator
import pickle
from extractData import knownPool
from walletAnalyser import stats_wallets,XMR_USD_EXCHANGE,get_samples_wallet,info_wallets,aggregate_hash_rate,plot_graph_dataframe,is_donation_wallet,data_from_samples,dataset,exchange_addresses

mining_tools = pickle.load(open('../data/miner-tools.pickle','rb'))

# These domains were reported in https://research.checkpoint.com/de-anonymizing-monero-mining-operation/ as the C&C campaign used for mining
domains_checkpoint_Kozlov=[
'osdsoft.com',
'ztracker.xyz',
'ztracker.club',
'ztracker.ml',
'ztracker.gq',
'xtracker.club']

#https://www.netskope.com/blog/technical-analysis-of-xbooster-parasitic-monero-miner/ -> SOME OF THE WALLETS FROM THE REPORT USE DOMAINS FROM OSDSoft. To-analyse...
domains_xbooster_botnet=[
'ytracker.cf'
]

#Extracting by observing the list of contacted domains used by wallets in https://www.netskope.com/blog/technical-analysis-of-xbooster-parasitic-monero-miner/
domains_xbooster_botnet_observed=[
'uy.ziten.ru.ovh.net',
'ztracker.ml.ovh.net',
'ztracker.ml',
#'rterybrstutnrsbberve.com',
'ztracker.gq',
#'erwbtkidthetcwerc.com',
'wirtok.com',
'ytracker.cf',
'xtracker.club.ovh.net',
'ztracker.xyz',
'uy.ziten.ru',
#'rvbwtbeitwjeitv.com',
'ztracker.online',
'xtracker.club',
'qtracker.tk',
'ytracker.tk'
]
#https://www.proofpoint.com/us/threat-insight/post/smominru-monero-mining-botnet-making-millions-operators
domains_smominru=[
'down.oo000oo.club',
'www.cyg2016.xyz',
'down.mys2016.info',
'wmi.mykings.top.info',
'wmi.oo000oo.club',
'xmr.5b6b7b.ru',
'64.myxmr.pw',
'wmi.my0709.xyz',
'ftp.ruisgood.ru',
'ftp.oo000oo.me',
'ftp.ftp0118.info',
'js.mys2016.info',
'down.my0709.xyz',
'down.my0115.ru',
'wmi.my0115.ru',
'js.my0115.ru',
'Xmr.xmr5b.ru',
'64.mymyxmra.ru',
'Down.down0116.info']

domains_xbooster_botnet_all=[
'uy.ziten.ru.ovh.net',
'ztracker.ml.ovh.net',
'ztracker.ml',
#'rterybrstutnrsbberve.com',
'ztracker.gq',
#'erwbtkidthetcwerc.com',
'wirtok.com',
'ytracker.cf',
'xtracker.club.ovh.net',
'ztracker.xyz',
'uy.ziten.ru',
#'rvbwtbeitwjeitv.com',
'ztracker.online',
'xtracker.club',
'qtracker.tk',
'ytracker.tk',
'osdsoft.com',
'ztracker.club'
]

# These  domains were reported in https://www.fireeye.com/blog/threat-research/2016/06/resurrection-of-the-evil-miner.html. They appeared hosting the pool information for the miner.
# https://www.guardicore.com/2016/06/the-photominer-campaign/
domains_photominer_campaign=[
'stafftest.ru',
'hrtests.ru',
'profetest.ru',
'testpsy.ru',
'pstests.ru',
'qptest.ru',
'prtests.ru',
'jobtests.ru',
'iqtesti.ru',
'managtest.ru',
'testswork.ru',
'www.testtrade.ru',
'www.tradetests.ru',
'worktests.ru']



# Domains reported as the jenkins campaign (https://research.checkpoint.com/jenkins-miner-one-biggest-mining-operations-ever-discovered/)
domains_jenkins_checkpoint_150218=[
'222.184.79.11',
'183.136.202.244',
'btc.poolbt.com',
'shell.poolbt.com',
'xmr.btgirl.com.cn',
'btc.btgirl.com.cn']

#https://www.symantec.com/connect/blogs/w32virut-using-cryptography-prevent-domain-hijacking
domains_virut_botnet=[
'camaltirestorant.com',
'ant.trenz.pl',
'ilo.brenz.pl'
]

#https://www.fireeye.com/blog/threat-research/2016/02/maimed_ramnit_still.html
#https://www.sophos.com/en-us/threat-center/threat-analyses/viruses-and-spyware/W32~Ramnit-A/detailed-analysis.aspx
domains_ramnit_botnet=[
'fget-career.com',
'rtvwerjyuver.com',
'supnewdmn.com',
'tvrstrynyvwstrtve.com',
'wqerveybrstyhcerveantbe.com'
]

#https://securingtomorrow.mcafee.com/mcafee-labs/digging-into-the-nitol-ddos-botnet/
#https://otx.alienvault.com/pulse/5acb6b8541e3db16f39e7948
domains_nitol_botnet=[
'zwx5060.3322.org',
'guangkuo119.3322.org',
'yezi999.3322.org',
'kankan902.3322.org',
'maple110.3322.org',
'mybaccy.3322.org',
'bcl5736120.3322.org',
'ylddos.3322.org',
'xiong97.3322.org',
'xinxin168.3322.org',
'sousou123.3322.org',
'maguss.3322.org',
'aisini1314.3322.org',
'fuck0313.6600.org',
'ksattack.6600.org',
'fangqi.6600.org',
'xin9liao.gnway.net',
'fangqi.7766.org',
'1.ccddos.net',
'rvbwtbeitwjeitv.com',
'rterybrstutnrsbberve.com',
'erwbtkidthetcwerc.com',
'pornoliks.com',
'promoliks.com',
'stromoliks.com',
'fkjdeljfeew32233.com',
'promoliks.combing.com',
'proxim.ircgalaxy.pl'
]
#https://www.proofpoint.com/us/threat-insight/post/adylkuzz-cryptocurrency-mining-malware-spreading-for-weeks-via-eternalblue-doublepulsar
domains_adylkuzz=[
'super5566.com',
'08.super5566.com',
'a1.super5566.com',
'aa1.super5566.com',
'07.super5566.com',
'super1024.com',
'lll.super1024.com',
'am.super1024.com',
'05.microsoftcloudserver.com',
'd.disgogoweb.com',
'panel.minecoins18.com',
'wa.ssr.la',
# Added after aggregation
'aaa.super1024.com'
]

domains_freebuf=[
'freebuf.info',
'alibuf.com'
]

domains_rocke=[
'sydwzl.cn',
'www.sydwzl.cn',
'blockbitcoin.com',
'dazqc4f140wtl.cloudfront',
'3g2upl4pq6kufc4m.tk',
'd3goboxon32grk2l.tk',
'enjoytopic.tk',
'realtimenews.tk',
'8282.space'
]
domains_51btc=['51btc.mobi']
domains_usa138=['usa-138.com']
domains_kryptex=['kryptex.org']
domains_shin3366=['shin3366.cc']
domains_1gpdmamkqlxez=['1gpdmamkqlxez.xyz']
domains_alnamrood=['alnamrood.ru','tsdjuuytw7udw.ru']
# Domains that are aliases of known pools (through CNAMEs)
da=list(set(list(pd.read_csv('../data/alternative_domains_pools.csv')['ALTERNATIVE_DOMAIN'])))
domains_aliases=[]
for d in da:
    domains_aliases.append(d.strip())

known_campaigns={
    # "ALIASES":domains_aliases,
    "RAMNIT":domains_ramnit_botnet,
    "VIRUT":domains_virut_botnet,
    "XBOOSTER":domains_xbooster_botnet_all,
    "JENKINS":domains_jenkins_checkpoint_150218,
    "PHOTOMINER":domains_photominer_campaign,
    "NITOL-BOTNET":domains_nitol_botnet,
    "SMOMINRU":domains_smominru,
    "ADYLKUZZ":domains_adylkuzz,
    'ROCKE':domains_rocke
}
known_campaigns_aliases={
    "FREEBUF":domains_freebuf,
    "51BTC.MOBI":domains_51btc,
    "USA-138.COM":domains_usa138,
    "KRYPTEX.ORG":domains_kryptex,
    "SHIN2266.CC":domains_shin3366,
    '1gpdmamkqlxez.XYZ':domains_1gpdmamkqlxez,
    'ALNAMROOD':domains_alnamrood
}

def get_campaign(hostname):
    for name,campaign in known_campaigns.items():
        for domain in campaign:
            if domain in hostname:
                return name
            # else:
            #   print "[%s] vs [%s]"%(domain,hostname)
    for altDomain in domains_aliases:
        if altDomain[-1]=='.':
            altDomain=altDomain[:-1]
        if len(altDomain.split('.'))>2:
            main_domain=".".join(altDomain.split('.')[-2:]).strip()
        else:
            main_domain=altDomain.strip()
        if main_domain in hostname:
            return "ALIASES"
    return "UN-CLASSIFIED"


# Returns two dictionaries where keys are domain names and values are list of samples querying for this domain (as seen in the network)
# First dictionary contains the known pools, second contain unknown domains
def domains_per_samples(snapshot='20180709'):
    out_file='../data/domains_per_samples.pickle'
    if not os.path.exists(out_file):
        data_from_samples_user = data_from_samples[(data_from_samples['DNSRR'].notnull() | data_from_samples['POOL'].notnull()) & data_from_samples['USER'].notnull()]

        unknownDomains={}
        knownPools={}
        for index, row in dns_ours_net.iterrows(): 
            sha256 = row['SHA256']
            domains= row['DNSRR']
            dns_tmp=[]
            for d in domains.split(']-['):
                dns_tmp.append(d.replace('[','').replace(']',''))
            if not 'nan' in str(row['POOL']):
                for d in row['POOL'].split(','):
                    dns_tmp.append(d)
            for hostname in list(set(dns_tmp)):
                if knownPool(hostname):
                    if not hostname in knownPools:
                        knownPools[hostname]=[]
                    knownPools[hostname].append(sha256)
                else:
                    if not hostname in unknownDomains:
                        unknownDomains[hostname]=[]
                    unknownDomains[hostname].append(sha256)
        pickle.dump((knownPools,unknownDomains),open(out_file,'wb'))
    else:
        knownPools,unknownDomains=pickle.load(open(out_file))
    return knownPools,unknownDomains


# Returns two dictionaries where keys are domain names and values are list of wallets querying for this domain (as seen in the network)
# First dictionary contains the known pools, second contain unknown domains
def domains_per_wallets():
    out_file='../data/domains_per_wallets.pickle'
    if not os.path.exists(out_file):
        data_from_samples_user = data_from_samples[(data_from_samples['DNSRR'].notnull() | data_from_samples['POOL'].notnull())  & data_from_samples['USER'].notnull()]
        # print data_from_samples_user[data_from_samples_user.POOL.notnull() & data_from_samples_user.POOL.str.contains('santananb')]['USER']
        # exit()
        unknownDomains={}
        knownPools={}
        
        for index, row in data_from_samples_user.iterrows(): 
            # if 'santananb' in str(row.POOL):
            #   print row
            #   exit()
            if index%1000==0:
                print "Processing index:%s out of %s"%(index,len(data_from_samples))

            # Normalize and take only Monero wallets
            wallet = row.USER
            wallets=[]
            if "," in wallet:
                for w in wallet.split(','):
                    if len(w)>90 and w[0]=='4':
                        if w.split('.')[0] in exchange_addresses and len(w.split('.'))>1:
                            wallets.append(".".join(w.split('.')[:2]).split('+')[0].split('/')[0].split(":")[0].split('@')[0])
                        else:
                            wallets.append(w.split('.')[0].split('+')[0].split('/')[0].split(":")[0].split(',')[0].split('@')[0])
            else:
                if len(wallet)>90 and wallet[0]=='4':
                    if wallet.split('.')[0] in exchange_addresses and len(wallet.split('.'))>1:
                        wallets.append(".".join(wallet.split('.')[:2]).split('+')[0].split('/')[0].split(":")[0].split('@')[0])
                    else:
                        wallets.append (wallet.split('.')[0].split('+')[0].split('/')[0].split(":")[0].split(',')[0].split('@')[0])
            if len(wallets)==0:
                continue
            domains= row.DNSRR
            dns_tmp=[]
            for d in domains.split(']-['):
                dns_tmp.append(d.replace('[','').replace(']',''))
            if str(row.POOL)!='nan':
                for d in str(row.POOL).split(','):
                    dns_tmp.append(d)
            for hostname in list(set(dns_tmp)):
                if knownPool(hostname):
                    if not hostname in knownPools:
                        knownPools[hostname]=[]
                    for wallet in wallets:
                        if not wallet in knownPools[hostname]:
                            knownPools[hostname].append(wallet)
                else:
                    if not hostname in unknownDomains:
                        unknownDomains[hostname]=[]
                    for wallet in wallets:
                        if not wallet in unknownDomains[hostname]:
                            unknownDomains[hostname].append(wallet)
        pickle.dump((knownPools,unknownDomains),open(out_file,'wb'))
    else:
        knownPools,unknownDomains=pickle.load(open(out_file))
    return knownPools,unknownDomains    

# Returns a dictionary where keys are pairs of items (either wallets or samples) and values are the common domains
def get_common_domains(data):
    common_domains={}
    for hostname in data:
        for i,item1 in enumerate(data[hostname]):
            for item2 in data[hostname][i+1:]:
                if (item1,item2) in common_domains: 
                    common_domains[(item1,item2)].append(hostname)
                elif (item2,item1) in common_domains:
                    common_domains[(item2,item1)].append(hostname)
                else:
                    common_domains[(item1,item2)]=[hostname]
    return common_domains
    

# Get the list of IPs associated with the pool.minexmr.com domain, and then queries threatcrowd for domains associated with these IPs in the past 
def check_domain_aliases(domain):
    ip_list = []
    ais = socket.getaddrinfo(domain,0,0,0,0)
    for result in ais:
      ip_list.append(result[-1][0])
    ip_list = list(set(ip_list))
    #print "DOMAIN,IP,LAST_RESOLVED,ALTERNATIVE_DOMAIN"
    for ip in ip_list:
        result =  requests.get("https://www.threatcrowd.org/searchApi/v2/ip/report/", params = {"ip": ip})
        j = json.loads(result.text)
        j = json.loads(result.text)
        if 'resolutions' in j:
            for r in j['resolutions']:
                if not r["domain"]==domain:
                    print "%s,%s,%s,%s"%(domain,ip,r["last_resolved"],r["domain"])


def samples_domain(domain):
    samples=data_from_samples[(data_from_samples['DNSRR'].notnull() & data_from_samples['DNSRR'].str.contains(domain)) | (data_from_samples['POOL'].notnull() & data_from_samples['POOL'].str.contains(domain))]['SHA256']
    return samples

    
def get_wallets_domains(domains,verbose=False):
    known,unknown = domains_per_wallets()
    wallets_campaign=[]
    data=unknown
    sorted_data=sorted(data, key=lambda k: len(data[k]), reverse=True)
    allSamples=[]
    # Look for contacted domains
    for i,k in enumerate(sorted_data):
        for domain in domains:
            if len(k)>0 and domain in k.lower():
                samples=samples_domain(k)
                if verbose: print "Domain: %s, Wallets:%d, Num Samples:%s"%(k,len(data[k]),len(samples))
                wallets_campaign.extend(data[k])
                allSamples.extend(samples)
        wallets_campaign=list(set(wallets_campaign))
        allSamples=list(set(allSamples))
    # Look for ITW_urls
    for sample in dataset:
        if 'ITW_urls' in dataset[sample] and dataset[sample]['ITW_urls'] is not None:
            for url in dataset[sample]['ITW_urls']:
                for domain in domains:
                    if domain in url.lower():
                        allSamples.append(sample)
                        values=data_from_samples.loc[(str(data_from_samples['SHA256'])==str(sample)) & (data_from_samples['USER'].notnull())]['USER'].values
                        if len(values)>0:
                            for w in values[0].split(','):
                                if len(w)>90 and w[0]=='4':
                                    if w.split('.')[0] in exchange_addresses and len(w.split('.'))>1:
                                        wallets_campaign.append(".".join(w.split('.')[:2]).split('+')[0].split('/')[0].split(":")[0].split('@')[0])
                                    else:
                                        wallets_campaign.append(w.split('.')[0].split('+')[0].split('/')[0].split(":")[0].split(',')[0].split('@')[0])
    return wallets_campaign,allSamples
def get_wallets_campaign(name):
    domains=known_campaigns[name]
    return get_wallets_domains(domains)

def analyse_campaign_by_wallets(name,wallets_campaign,latex=True,show_per_wallet_info=False,include_hash_rate=False):
    totalPaid,totalSamples,totalWallets,poolData,totalUSD=stats_wallets(wallets_campaign,numTab=0,verbose=show_per_wallet_info)
    if include_hash_rate:
        dataframe_graph,numGraphs,median,mean,maximum,maximumDate,minimum=aggregate_hash_rate(wallets_campaign,verbose=False)
        print "AGGREGATED STATS OF %s GRAPHS"%numGraphs
        print "Median: %.2f"%median
        print "Mean: %.2f"%mean
        print "Min: %.2f"%(minimum)
        print "Max: %.2f (%s)"%(maximum,maximumDate)    
        plot_graph_dataframe(dataframe_graph,name)
    if latex:
        firstPayment=datetime.now()
        lastActivity=datetime(1999,1,1)
        pools=[]
        for wallet in poolData:
            
            for poolInfo in poolData[wallet]:
                if not poolInfo['POOL'] in pools:
                    pools.append(poolInfo['POOL'])
                if poolInfo['FIRST_PAYMENT'] and poolInfo['FIRST_PAYMENT']<firstPayment:
                    firstPayment=poolInfo['FIRST_PAYMENT']
                if poolInfo['LAST_PAYMENT'] and poolInfo['LAST_PAYMENT']>=lastActivity:
                    lastActivity=poolInfo['LAST_PAYMENT']
                if not str(poolInfo['LAST_SHARE'])=='nan' and datetime.strptime (poolInfo['LAST_SHARE'],"%Y-%m-%d")>=lastActivity:
                    lastActivity=datetime.strptime (poolInfo['LAST_SHARE'],"%Y-%m-%d")
    
        #NAME,NUM_SAMPLES,NUM_WALLETS,ACTIVITY_PERIOD,POOLS,TOTAL_MINED
        print '{} & {} & {} & {} to {} & \\begin{{minipage}}{{2in}}{}\\end{{minipage}} & {:.2f} & {:.2f}\\\\'.format(name,len(allSamples),totalWallets,firstPayment.strftime('%d/%m/%Y'),lastActivity.strftime('%d/%m/%Y'),", ".join(pools),totalPaid,totalUSD)
    else:
        print "TOTAL:{:,.2f} XMR ({:,.2f} USD), {} samples, {} wallets".format(totalPaid,totalUSD,totalSamples, totalWallets)     

# Given a campaigns name, print the aggregated earnings of the wallets querying to these domains
def analyse_campaign_by_name(name,numCampaign=-1,latex=True,show_per_wallet_info=False,include_hash_rate=False):
    wallets_campaign,allSamples=get_wallets_campaign(name)
    analyse_campaign_by_wallets(name,wallets_campaign,latex=latex,show_per_wallet_info=show_per_wallet_info,include_hash_rate=include_hash_rate)
    return wallets_campaign

# Given a list of wallets, returns the domains queried by these in form of a dict of wallets with the domains, and a list with all the domains
def get_domains_wallets(wallets,data):
    wallet_domains={}
    allDomains=[]
    for hostname in data:
        if len(hostname)==0:
            continue
        for w in data[hostname]:
            if w in wallets:
                if not w in wallet_domains: 
                    wallet_domains[w]=[]
                wallet_domains[w].append(hostname)
                if not hostname in allDomains:
                    allDomains.append(hostname)
    return wallet_domains,allDomains

def get_activity_period(poolData):
    firstPayment=datetime.now()
    foundFirst=False
    lastActivity=datetime(1999,1,1)
    foundLast=False
    pools=[]
    for wallet in poolData:
        for poolInfo in poolData[wallet]:
            if not poolInfo['POOL'] in pools:
                pools.append(poolInfo['POOL'])
            if poolInfo['FIRST_PAYMENT'] and poolInfo['FIRST_PAYMENT']<firstPayment:
                firstPayment=poolInfo['FIRST_PAYMENT']
                foundFirst=True
            if poolInfo['LAST_PAYMENT'] and poolInfo['LAST_PAYMENT']>=lastActivity:
                lastActivity=poolInfo['LAST_PAYMENT']
                foundLast=True
            if not str(poolInfo['LAST_SHARE'])=='nan' and datetime.strptime (poolInfo['LAST_SHARE'],"%Y-%m-%d")>=lastActivity:
                lastActivity=datetime.strptime (poolInfo['LAST_SHARE'],"%Y-%m-%d")
                foundLast=True
    if not foundFirst:
        firstPayment=None
    return firstPayment,lastActivity
# Processes the list of aliases and for each of them checks the number of wallets using it
def campaigns_based_on_aliases(n=10,printCSV=False,latex=True):
    known,unknown = domains_per_wallets()
    data=unknown
    csv_data=[]
    if printCSV:
        print "ALTERNATIVE_DOMAIN,DOMAIN,NUM_WALLETS,TOTAL_PAID,TOTAL_SAMPLES_WALLETS,TOTAL_SAMPLES_DOMAIN"
    sorted_domain_aliases=sorted(domains_aliases)
    mainDomainsProcessed={}
    for altDomain in domains_aliases:
        if altDomain[-1]=='.':
            altDomain=altDomain[:-1]
        if len(altDomain.split('.'))>2:
            main_domain=".".join(altDomain.split('.')[-2:]).strip()
        else:
            main_domain=altDomain.strip()
        if main_domain in mainDomainsProcessed:
            continue
        wallets=[]
        for i,k in enumerate(data):
            if len(k)>0 and main_domain.lower() in k.lower():
                wallets.extend(data[k])
        if len(wallets)==0:
            continue
        samples=samples_domain(main_domain)
        numSamples=len(samples)
        wallets=list(set(wallets))
        totalPaid,totalSamples,totalWallets,poolData=stats_wallets(wallets,numTab=0,verbose=False)
        mainDomainsProcessed[main_domain]={'totalPaid':totalPaid,'totalSamples':numSamples,'totalWallets':totalWallets,'wallets':wallets,'poolData':poolData}
        #print "%s,%s,%s,%s"%(main_domain,totalPaid,totalSamples,totalWallets)

    sorted_main_domains=sorted(mainDomainsProcessed,key=lambda k: mainDomainsProcessed[k]['totalPaid'],reverse=True)
    for domain in sorted_main_domains[:n]:
        if latex:
            firstPayment,lastActivity=get_activity_period(mainDomainsProcessed[domain]['poolData'])
            print '{} & {} & {} & {} to {} & \\begin{{minipage}}{{2in}}{}\\end{{minipage}} & {:.2f} & {:.2f}\\\\'.format(domain,mainDomainsProcessed[domain]['totalSamples'],mainDomainsProcessed[domain]['totalWallets'],firstPayment.strftime('%d/%m/%Y'),lastActivity.strftime('%d/%m/%Y'),", ".join(pools),mainDomainsProcessed[domain]['totalPaid'],mainDomainsProcessed[domain]['totalPaid']*XMR_USD_EXCHANGE)
        elif not printCSV:
            print "[%s] Paid=%.2f XMR (%.2f USD) Num wallets=%s Num samples=%s"%(domain,mainDomainsProcessed[domain]['totalPaid'], (mainDomainsProcessed[domain]['totalPaid']*XMR_USD_EXCHANGE),mainDomainsProcessed[domain]['totalWallets'],mainDomainsProcessed[domain]['totalSamples'])
            for w in sorted(mainDomainsProcessed[domain]['wallets']):
                print "\t"+w

# Aggregates the wallets based on the contacted domains if these are not part of a knonw campaign
def campaigns_based_on_unclassified_domains(printCSV=False):
    known,unknown = domains_per_wallets()
    csv_data=[]
    data={}
    for hostname in unknown:
        if len(hostname)==0:
            continue
        known_domain=False
        for campaign in known_campaigns.values():
            for domain in campaign:
                if domain in hostname:
                    known_domain=True
                    break
                if known_domain: break
        if not known_domain:
            if not printCSV:
                data[hostname]=len(unknown[hostname])
                #print "%s -> %s wallets"%(hostname,len(unknown[hostname]))

                #totalPaid,totalSamples,totalWallets=stats_wallets(unknown[hostname],numTab=1,verbose=True)
            else:
                hostnamePrint=hostname
                try:
                    answers = dns.resolver.query(hostname,'CNAME')
                    cnames=""
                    for a in answers:
                        cnames+=str(a)+","
                    cnames=cnames[:-1]
                    hostnamePrint=hostname+" (CNAME OF %s)"%cnames
                except:
                    pass    
                totalPaid,totalSamples,totalWallets,poolData=stats_wallets(unknown[hostname],numTab=0,verbose=False)
                csv_data.append((hostnamePrint,len(unknown[hostname]),totalPaid,totalSamples,totalWallets))
    if printCSV:
        csv_data=list(set(csv_data))
        for item in csv_data:
            print "%s,%s,%.5f,%s,%s"%item               
    else:
        ordered_data=sorted(data.items(),key=operator.itemgetter(1),reverse=True)
        for hostname,numWallets in ordered_data:
            hostnamePrint=hostname
            try:
                answers = dns.resolver.query(hostname,'CNAME')
                cnames=""
                knownPool=False
                for a in answers:
                    if knownPool(a):
                        knownPool=True
                    cnames+=str(a)+","
                cnames=cnames[:-1]
                hostnamePrint=hostname+" (CNAME OF %s)"%cnames
                if knownPool:
                    hostnamePrint+=' ALIAS OF KNOWN POOL'
            except:
                pass    
            numSamples=len(samples_domain(hostname))
            print "%s -> %s wallets, %s samples"%(hostnamePrint,len(unknown[hostname]),numSamples)
            totalPaid,totalSamples,totalWallets,poolData=stats_wallets(unknown[hostname],numTab=1,verbose=True)

def graph_campaigns(by="WALLET",only_monero=True,only_with_wallets=True):
    G = nx.Graph()
    for campaign_name,domains in known_campaigns.items():
        G.add_node(campaign_name, label=campaign_name, color='black', fillcolor='red', style='filled')
    itemsCampaigns={}
    if (only_with_wallets):
        data=data_from_samples[data_from_samples['DNSRR'].notnull() & data_from_samples['USER'].notnull()]
    else:
        data=data_from_samples[data_from_samples['DNSRR'].notnull()]

    for i,value in data.iterrows():
        thisDomains=value['DNSRR'].split(']-[')
        if by=='WALLET':
            item=value['USER']
            if only_monero:
                if len(item)>90 and item[0]=='4':
                    if item.split('.')[0] in exchange_addresses and len(item.split('.'))>1:
                        item=".".join(item.split('.')[:2]).split('+')[0].split('/')[0].split(":")[0].split('@')[0] 
                    else:
                        item = item.split('.')[0].split('+')[0].split('/')[0].split(":")[0].split('@')[0]
                else:
                    continue
        else:
            item=value['SHA256']
        for d in thisDomains:
            thisDomain=d.replace('[','').replace(']','')
            for campaign_name,campaign_domains in known_campaigns.items():  
                for domain in campaign_domains:
                    if domain.lower() in thisDomain.lower():
                        wallet_sample=str(value['USER'])
                        if wallet_sample!='nan':
                            if only_monero:
                                if "," in wallet_sample:
                                    wallet_sample_tmp=""
                                    for w in wallet_sample.split(','):
                                        if len(w)>90 and w[0]=='4':
                                            if w.split('.')[0] in exchange_addresses and len(w.split('.'))>1:
                                                wallet_sample_monero=".".join(w.split('.')[:2]).split('+')[0].split('/')[0].split(":")[0].split('@')[0] 
                                            else:
                                                wallet_sample_monero = w.split('.')[0].split('+')[0].split('/')[0].split(":")[0].split('@')[0]
                                            wallet_sample_tmp+=wallet_sample_monero+','
                                    if len(wallet_sample_tmp)==0:
                                        wallet_sample=None
                                    else:
                                        wallet_sample=wallet_sample_tmp[:-1]
                                elif len(wallet_sample)>90 and wallet_sample[0]=='4':
                                    if wallet_sample.split('.')[0] in exchange_addresses and len(wallet_sample.split('.'))>1:
                                        wallet_sample=".".join(wallet_sample.split('.')[:2]).split('+')[0].split('/')[0].split(":")[0].split('@')[0] 
                                    else:
                                        wallet_sample = wallet_sample.split('.')[0].split('+')[0].split('/')[0].split(":")[0].split('@')[0]
                                else:
                                    wallet_sample=None
                        else:
                            wallet_sample=None

                        if not only_with_wallets or wallet_sample is not None:
                            node_color = 'gray'
                            if wallet_sample is not None:
                                node_color='blue'
                            if "," in item:
                                for i in item.split(','):
                                    if not i in list(G.nodes):
                                        G.add_node(i, label='',wallet=wallet_sample, color='black', fillcolor=node_color, style='filled')
                                    G.add_edge(i, campaign_name, weight=1, color='black')
                            else:
                                if not item in list(G.nodes):
                                    G.add_node(item, label='',wallet=wallet_sample, color='black', fillcolor=node_color, style='filled')
                                G.add_edge(item, campaign_name, weight=1, color='black')
                        #print "\t%s"%w
    outfile =  '../data/graph_wallets_domains_by%s.gexf'%by

    if only_with_wallets:
        outfile = outfile.replace('.gexf', '_only-with_wallets.gexf')

    if only_with_wallets:
        outfile = outfile.replace('.gexf', '_only-monero.gexf')

    print '----- Dumping', outfile
    print len(G.edges())
    print len(G.nodes())
    nx.write_gexf(G, outfile) 

    return G

def createCampaignData(filename):
    # KNOWN CAMPAIGNS
    if not os.path.exists(filename):
        campaigns={}
        print "----KNOWN CAMPAIGNS----"
        for i,name in enumerate(known_campaigns):
            wallets_campaign,allSamples=get_wallets_campaign(name)
            campaigns['BOTNET-'+name]={'wallets':wallets_campaign,'samples':allSamples}
            print "Campaign %s: %s (%s wallets, %s samples)"%(i,name,len(wallets_campaign),len(allSamples))
        print "----KNOWN CAMPAIGNS ALIASES----"
        i=i+1
        for name in known_campaigns_aliases:
            wallets_campaign,allSamples=get_wallets_domains(known_campaigns_aliases[name])
            campaigns['ALIAS-'+name]={'wallets':wallets_campaign,'samples':allSamples}
            print "Campaign %s: %s (%s wallets, %s samples)"%(i,name,len(wallets_campaign),len(allSamples))
            i=i+1
        # ALIASES
        print
        print "------OTHER ALIASES-----"
        for alias in domains_aliases:
            if len(alias)==0:
                continue
            known_domain=False
            for campaign in known_campaigns.values():
                for domain in campaign:
                    if domain in alias or alias in domain:
                        known_domain=True
                        break
                    if known_domain: break
            for campaign in known_campaigns_aliases.values():
                for domain in campaign:
                    if domain in alias or alias in domain:
                        known_domain=True
                        break
                    if known_domain: break
            if not known_domain:
                wallets_campaign,allSamples=get_wallets_domains([alias])
                if len(wallets_campaign)>0 or len(allSamples)>0:
                    print "Campaign %s: %s (%s wallets, %s samples)"%(i,alias,len(wallets_campaign),len(allSamples))
                    campaigns['ALIAS-'+alias]={'wallets':wallets_campaign,'samples':allSamples}
                    i=i+1
        pickle.dump(campaigns,open(filename,'wb'))
    else:
        print "%s already exists. Remove if you want to overwrite"%filename


def allCampaignsToLatex():

    print "\\begin{table*}"
    print "\\center"
    print "\\caption{Summary of campaigns based in CNAMES}"
    print "\\label{table:campaigns-domains}"
    print "\\begin{tabular}{cSSccSS}"
    print "Campaign & {\\#Samples} & {\\#Wallets} & Active Period & Pools & {Total XMR} & {Total USD} \\\\"
    print "\\hline"
    campaigns_based_on_aliases(n=10)
    print "\\end{tabular}"
    print "\\end{table*}"   

def print_domains_top_paid(n=30):
    wallets_with_paid= info_wallets[info_wallets['TOTAL_PAID'].notnull()]
    dataFrame=pd.DataFrame(wallets_with_paid.groupby(['USER'])['TOTAL_PAID'].agg('sum'))
    wallets=list(dataFrame.sort_values(by=['TOTAL_PAID'],ascending=False).index.values)[:n]
    print "DOMAINS OF TOP %s WALLETS:"%n
    known,unknown = domains_per_wallets()
    wallet_domains,allDomains=get_domains_wallets(wallets,unknown)
    for w in wallets:
        print "%s (TOTAL PAID=%.2f):"%(w,dataFrame.loc[w]['TOTAL_PAID'])
        if w in wallet_domains:
            for domain in wallet_domains[w]:
                campaign=get_campaign(domain)
                print "\t%s (%s)"%(domain,campaign)
        else:
            print '\t[NO DOMAINS FOUND]'
def stats_banned_wallets():
    wallets_connection={'46hwtP8R9YaZwTdWuozJAyMQRSw82tEYkg5FSWqikTxkJNKXKyVmGn57UZR3Agfvwx9GwmHP5Qby1hKek2u3M738AVCS192':1052,
'4AuKPF4vUMcZZywWdrixuAZxaRFt9FPNgcv9v8vBnCtcPkHPxuGqacfPrLeAQWKZpNGTJzxKuKgTCa6LghSCDrEyJ5s7dnW':1193,
'43rfEtGjJdFaXDjRYvo7wJ9Cmq1vWjMdkZzaKEkgp4aQBHKhKZ7Rp6oB1QMBPFJUKGGWc9AeAbr9V6gYVSM8XwbXBYZXBss':1204,
'42FhyWmACvj4HDrWYqn6HY2stcfDq9srgKV2Du3W5FgUVdCLH9bmzgTMGELVWAT8iyMBYRGL6P7SH8FnhebQoXcPACegmio':1698,
'43g4oCS2wjuQN4ZWaycJtm3HKVs4LTeBxSs81B2YMiNbgaMTK7LuzYAhFdZJmhkU8P4iRBYHFz9FEcHeiKLtBBYrHV66Rnr':1971,
'48np7fEXZBwPVzhDk5MeZoai4iLAAharXK62ziZe8SFpdmGW87n8GHoTxC5RftYLqwQNaSUjj5bHvXUTVBWgsm7PTBW7xM3':2156,
'48oH4ogbgWSFwujsWY5qcUecLvwfLvRvtCksUahJdZjNSqKiYNJmmGJfMNX2LeJGjYdYHgNLLaNYEQW8rvrCQoVLLudWHVV':3115,
'44GKHbTfrkSZo9SKMDT1n6RtekRXqFwLghPUMQ83yp7CVadobZ81LdZckGnRkeg2AL4wdze2f645rDiRkRQY7G3xS7bQ5z4':3751,
'478skBePM6FE8Pd1MQjHw9NueMG7F6SHoFWXHYp5oyw8X3geYQsUf9FESJVdgHaPxCTEPt99vpTxDPMymxVjMFEc5JUENHc':3966,
'44GTa6YFX7meL353eWgG9xjezrWNQ1nZq4hsgGsi5wk27PYhutWtnGDfg9RTYcgnoefNJG9vDyfkpdADTLWnFeyCH1zNp5R':4605,
'45WVNRZkKoR55thZWviZ3diXBLAcNRp4yFCtDCnCLRL7bq9E7XqQ7GX5auuc8thCvgUv1av6MpgC5gFVECYGHmx1VKkfEnp':5352,
'45c2ShhBmuk6ukfdTLok59U86gWLXZo8kDJbpTm8uYT1U35mig1pUCbd6796AJviTPXetFrUo37XFGcEYU1k3tYe32o9qEr':8099,
'48eWXu6LzJwXDeDv5zgq1RZ5Lgy7DxhxneAR6n4caPNfUACHVw54vVkEm77aWowSk7b5JUnosGuBzVJJGfbVmBDPNgVLNRi':13060,
'49e9B8HxzSbMWsNbMs72aVe78U9CCE2DAM5aDJYNeccWNvWiKfrPaGeewmTAjj6nt6Bqzob4zaRjLXfpW1WfRMnzEAQBHy7':13292,
'47Tscy1QuJn1fxHiBRjWFtgHmvqkW71YZCQL33LeunfH4rsGEHx5UGTPdfXNJtMMATMz8bmaykGVuDFGWP3KyufBSdzxBb2':65821,
'44jL87F4hbcF7SXFq7A686cgnSRSrcwBP6qmMfTzpBJs2Pwgnogj2dmYHVkv4fyzLMHhSwWo1fWnBXQjQ7MVzcMcAS917WL':0,
'47h2VtXhf8zDSq8YAPrBeNj8nGTsCMg7pD4zF9pYE5ze6Djw86dctoz41Y9mW2EijXa8mvXUo52mu7pi2EAjbaWC2ZRuqJ7':0,
'49ER579mEyp4Mxq8NW8AfmX4KcXN1S6urWGdSmCrfittYEkoHLEgJaiUqbNA6LDrSL1QPbuLMPYMQB4e5YApiQbkKofE1i1':0,
'4AbjKdQkedGZXvzm6VxMJb1zLB2CAmCmXdoCisRsQFAUPs4TWFePDUcZzk5ui4EdZXT3uaXXtssqPCoKQPTz7PeZNkKASkm':0,
'4AkaMg1GxEfBXDCvBzr8KUFpVuTJKXwCGM3QGzLyHbphjeJk1hy5eukJiYmt1wU7gXapHPr1R6uiyJLkPjyYQEd8NstghGB':0,
'4JUdGzvrMFDWrUUwY3toJATSeNwjn54LkCnKBPRzDuhzi5vSepHfUckJNxRL2gjkNrSqtCoRUrEDAgRwsQvVCjZbRvmDrkhy5f4FwFWTtE':0
}
    wallets=wallets_connection
    wallets_with_paid= info_wallets[info_wallets['TOTAL_PAID'].notnull()]
    dataFrame=pd.DataFrame(wallets_with_paid.groupby(['USER'])['TOTAL_PAID'].agg('sum'))
    known,unknown = domains_per_wallets()
    wallet_domains,allDomains=get_domains_wallets(wallets,unknown)
    for w in wallets:
        print "%s (TOTAL PAID=%.2f Number of connections=%s):"%(w,dataFrame.loc[w]['TOTAL_PAID'],wallets_connection[w])
        if w in wallet_domains:
            for domain in wallet_domains[w]:
                campaign=get_campaign(domain)
                print "\t%s (%s)"%(domain,campaign)
        else:
            print '\t[NO DOMAINS FOUND]'

### CALL THE FUNCTIONS HERE ####
if __name__ == "__main__" :
    createCampaignData('../data/campaigns_based_on_domains.pickle')                    

