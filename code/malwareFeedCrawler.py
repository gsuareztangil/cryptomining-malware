import feedparser
from datetime import datetime
import requests
from requests import ConnectionError
import sys
import os
import signal
from selenium import webdriver

timeout=60
tsFormat='%Y%m%d_%H%M%S'
userAgent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10.11; rv:57.0) Gecko/20100101 Firefox/57.0'
headers=requests.utils.default_headers()
headers.update({'User-Agent': userAgent})

outputDir="OUT/DIR/HERE"
def alarmHandler (signum,frame):
	raise Exception('Timeout')
def downloadFile(src_url, dest_path, md5, simple=False):
	signal.signal(signal.SIGALRM, alarmHandler)
	if not os.path.exists(dest_path):
		os.makedirs(dest_path)	
	print "%s Downloading file from %s"%(datetime.now().strftime(tsFormat),src_url)
	signal.alarm(timeout)
	try:
		r = requests.get(src_url, stream=True,headers=headers)
		signal.alarm(0)
	except ConnectionError as e:
		print "%s ERROR. Cannot connect to URL %s"%(datetime.now().strftime(tsFormat),src_url)
		return 1
	except Exception as e:
		print "%s ERROR. Connection timeout (%s seconds)"%(datetime.now().strftime(tsFormat),timeout)	
		return 1
	if r.status_code<200 or r.status_code>299:
		print "%s ERROR. Code %s received for request on URL %s"%(datetime.now().strftime(tsFormat),r.status_code,src_url)
		return 1
	else:
		pass;
		#print "%s Response received from %s"%(datetime.now().strftime(tsFormat),src_url)
	outfname = os.path.join(dest_path+md5)
	with open(outfname, "wb") as outfile:
		if not simple:
			size_downloaded = 0
			size_total = len(r.content)
			for chunk in r.iter_content(chunk_size=8192):
				if chunk:
					outfile.write(chunk)
					size_downloaded += len(chunk)
					progress=size_downloaded * 100. / size_total
			# 		sys.stdout.write ("%s Writing to disk %s %10d  [%3.2f%%] \r"%(datetime.now().strftime(tsFormat),src_url,size_downloaded, progress))
			# 		sys.stdout.flush()
			# print
		else:
			print "%s Writing to disk %s..." % (datetime.now().strftime(tsFormat),src_url),
			shutil.copyfileobj(r.raw, outfile)
	print "%s Done. Saved to %s"%(datetime.now().strftime(tsFormat),outfname)
	return 0

def crawlVxvault():
	dirName=outputDir+"vxvault/"
	infoFile=dirName+"malwareInfo.csv"
	print ("%s Crawling Vxvault local file"%datetime.now().strftime(tsFormat))
	driver=webdriver.PhantomJS()
	driver.get('http://vxvault.net/ViriList.php?s=0&m=500000')
	rows=driver.find_elements_by_xpath('//div[@id="page"]/table/tbody/tr')[1:]
	print "%s Found %s samples"%(datetime.now().strftime(tsFormat),len(rows))
	for row in rows:
		columns=row.find_elements_by_tag_name('td')
		date=columns[0].text
		url=columns[1].find_elements_by_tag_name('a')[-1].text
		md5=columns[2].text
		fileURL="http://vxvault.net/files/"+columns[1].find_element_by_tag_name('a').get_attribute('href').split('/')[-1]
		ip=columns[3].text
		print ("MD5:%s\nURL:%s\nIP:%s\nDATE:%s"%(md5,url,ip,date))
		if not os.path.exists(dirName+md5):
		    status=downloadFile ('http://'+url,dirName,md5)
                else:
                    status=2
                    print "%s Sample already downloaded"%datetime.now().strftime(tsFormat)
    		fd=open(infoFile,'a+')
                fd.write("%s,%s,%s,%s,%s\n"%(md5,url,ip,date,status))	
		fd.close()
                print
 

def crawlMalc0de():
	dirName=outputDir+"Malc0de/"
	infoFile=dirName+"malwareInfo.csv"
	print ("%s Crawling Malc0de feed"%datetime.now().strftime(tsFormat))
	d=feedparser.parse('http://malc0de.com/rss/')
	for e in d['entries']:
		url= e['summary_detail']['value'].split(':')[1].split(',')[0].strip()
		ip= e['summary_detail']['value'].split(':')[2].split(',')[0].strip()
		country= e['summary_detail']['value'].split(':')[3].split(',')[0].strip()
		asn= e['summary_detail']['value'].split(':')[4].split(',')[0].strip()
		md5= e['summary_detail']['value'].split(':')[5].split(',')[0].strip()
		print ("MD5:%s\nURL:%s\nIP:%s\nCountry:%s\nASN:%s"%(md5,url,ip,country,asn))
		if not os.path.exists(dirName+md5):
			status=downloadFile ('http://'+url,dirName,md5)
			fd=open(infoFile,'a+')
			fd.write("%s,%s,%s,%s,%s,%s\n"%(md5,url,ip,country,asn,status))
			fd.close()
		else:
			print "%s Sample already downloaded"%datetime.now().strftime(tsFormat)
		print 
		
if __name__ == "__main__" :
	crawlMalc0de()
	crawlVxvault()
